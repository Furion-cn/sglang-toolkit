apiVersion: v1
kind: Service
metadata:
  name: {NAME}-prefill
  namespace: inference-system
  labels:
    app: {NAME}-prefill
spec:
  ports:
    - name: server 
      port: 30000
      targetPort: 30000
      protocol: TCP
  clusterIP: None
  selector:
    app: {NAME}-prefill
---
apiVersion: v1
kind: Service
metadata:
  name: {NAME}-decode
  namespace: inference-system
  labels:
    app: {NAME}-decode
spec:
  ports:
    - name: server
      port: 30000
      targetPort: 30000
      protocol: TCP
  clusterIP: None
  selector:
    app: {NAME}-decode
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {NAME}-prefill
  namespace: inference-system
spec:
  selector:
    matchLabels:
      app: {NAME}-prefill # has to match .spec.template.metadata.labels
  replicas: {PREFILL_REPLICA} # by default is 1
  serviceName: {NAME}-prefill
  template:
    metadata:
      labels:
        app: {NAME}-prefill # has to match .spec.selector.matchLabels
        server: {NAME}
    spec:
      terminationGracePeriodSeconds: 10
      dnsPolicy: "None"
      dnsConfig:
        nameservers:
          - 10.96.0.10
        searches:
          - cluster.local
          - svc.cluster.local
          - inference-system.svc.cluster.local
          - {NAME}-prefill.inference-system.svc.cluster.local
          - {NAME}-decode.inference-system.svc.cluster.local
        options:
          - name: ndots
            value: "5"
      containers:
      - name: {NAME}
        image: {IMAGE}
        imagePullPolicy: Always
        command: ["bash", "/scripts/entrypoint.sh"]
        resources:
          requests:
            nvidia.com/gpu: {PREFILL_GPU}
            rdma/hca_shared_devices: "1"
          limits:
            nvidia.com/gpu: {PREFILL_GPU}
            rdma/hca_shared_devices: "1"
        ports:
        - containerPort: 30000
          name: server
        volumeMounts:
        - name: result-path
          mountPath: /data/benchmark/results
        - name: model-path
          mountPath: /models
        - name: shm-volume
          mountPath: /dev/shm
        - name: script-path
          mountPath: /pd/scripts
        securityContext:
          privileged: true
          #capabilities:
          #  add: [ "IPC_LOCK" ]
        env:
        - name: MAX_CONCURRENCIES
          value: "{MAX_CONCURRENCIES}"
        - name: NCCL_SOCKET_IFNAME
          value: "eth0"
        - name: NCCL_DEBUG
          value: "INFO"
        - name: TP
          value: "{PREFILL_TP}"
        - name: DP
          value: "{PREFILL_DP}"
        - name: ENABLE_DEEPEP
          value: "1"
        - name: WORLD_SIZE
          value: "{PREFILL_REPLICA}"
        - name: GLOO_SOCKET_IFNAME
          value: "eth0"
        - name: MODEL_PATH
          # value: "/models/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
          value: "/models/DeepSeek-R1-BF16"
        - name: COMPILE_OPTS
          value: "--disable-cuda-graph --log-level debug"
        - name: MEM_FRACTION_STATIC
          value: "0.8"
        - name: PD_ROLE
          value: "{PREFILL_PD_ROLE}"
        - name: SERVER_NAME
          value: "{NAME}"
        - name: NVSHMEM_HCA_LIST
          value: "mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1"
        - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
          value: "1"
        - name: NCCL_IB_HCA
          value: "mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1"
        - name: KV_TRANSFER_DEVICE
          value: "mlx5_0,mlx5_1,mlx5_2,mlx5_3,mlx5_4"
        - name: SGLANG_SET_CPU_AFFINITY
          value: "1"
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      volumes:
        - name: result-path
          hostPath:
            path: /data/benchmark/results
        - name: model-path
          hostPath:
            path: /data
        - name: shm-volume
          emptyDir:
            medium: Memory
        - name: script-path
          hostPath:
            path: /root/hz/scripts
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {NAME}-decode
  namespace: inference-system
spec:
  selector:
    matchLabels:
      app: {NAME}-decode # has to match .spec.template.metadata.labels
  replicas: {DECODE_REPLICA} # by default is 1
  serviceName: {NAME}-decode
  template:
    metadata:
      labels:
        app: {NAME}-decode # has to match .spec.selector.matchLabels
        server: {NAME}
    spec:
      terminationGracePeriodSeconds: 10
      dnsPolicy: "None"
      dnsConfig:
        nameservers:
          - 10.96.0.10
        searches:
          - cluster.local
          - svc.cluster.local
          - inference-system.svc.cluster.local
          - {NAME}-prefill.inference-system.svc.cluster.local
          - {NAME}-decode.inference-system.svc.cluster.local
        options:
          - name: ndots
            value: "5"
      containers:
      - name: {NAME}
        image: {IMAGE}
        command: ["bash", "/scripts/entrypoint.sh"]
        imagePullPolicy: Always
        resources:
          requests:
            nvidia.com/gpu: {DECODE_GPU}
            rdma/hca_shared_devices: "1"
          limits:
            nvidia.com/gpu: {DECODE_GPU}
            rdma/hca_shared_devices: "1"
        ports:
        - containerPort: 30000
          name: server
        volumeMounts:
        - name: result-path
          mountPath: /data/benchmark/results
        - name: model-path
          mountPath: /models
        - name: shm-volume
          mountPath: /dev/shm
        - name: script-path
          mountPath: /pd/scripts
        securityContext:
          privileged: true
         # capabilities:
         #   add: [ "IPC_LOCK" ]
        env:
        - name: MODEL_PATH
          # value: "/models/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct"
          value: "/models/DeepSeek-R1-BF16"
        - name: NCCL_SOCKET_IFNAME
          value: "eth0"
        #- name: NCCL_DEBUG
        #  value: "INFO"
        - name: TP
          value: "{DECODE_TP}"
        - name: DP
          value: "{DECODE_DP}"
        - name: WORLD_SIZE
          value: "{DECODE_REPLICA}"
        - name: ENABLE_DEEPEP
          value: "1"
        - name: GLOO_SOCKET_IFNAME
          value: "eth0"
        - name: COMPILE_OPTS
          #value: "--enable-torch-compile --cuda-graph-max-bs 128 --torch-compile-max-bs 128 --cuda-graph-bs 1 2 3 4 15 16 126 127 128 --max-running-requests 2048 --log-level debug"
          value: "--disable-cuda-graph --max-running-requests 2048 --log-level debug"
        - name: MEM_FRACTION_STATIC
          value: "0.85"
        - name: NVSHMEM_HCA_LIST
          value: "mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1"
        - name: NVSHMEM_ENABLE_NIC_PE_MAPPING
          value: "1"
        - name: NCCL_IB_HCA
          value: "mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1"
        - name: KV_TRANSFER_DEVICE
          value: "mlx5_0,mlx5_1,mlx5_2,mlx5_3,mlx5_4"
        - name: SGLANG_SET_CPU_AFFINITY
          value: "1"
        - name: PD_ROLE
          value: "{DECODE_PD_ROLE}"
        - name: SERVER_NAME
          value: "{NAME}"
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      volumes:
        - name: model-path
          hostPath:
            path: /data
        - name: result-path
          hostPath:
            path: /data/benchmark/results
        - name: shm-volume
          emptyDir:
            medium: Memory
        - name: script-path
          hostPath:
            path: /root/hz/scripts
---
apiVersion: v1
kind: Service
metadata:
  name: {NAME}-minilb
  namespace: inference-system
  labels:
    app: {NAME}-minilb
spec:
  ports:
    - name: server
      port: 8000
      targetPort: 8000
      protocol: TCP
  selector:
    app: {NAME}-minilb
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {NAME}-minilb
  namespace: inference-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {NAME}-minilb
  template:
    metadata:
      labels:
        app: {NAME}-minilb
    spec:
      terminationGracePeriodSeconds: 10
      dnsPolicy: "None"
      dnsConfig:
        nameservers:
          - 10.96.0.10
        searches:
          - cluster.local
          - svc.cluster.local
          - inference-system.svc.cluster.local
          - {NAME}-prefill.inference-system.svc.cluster.local
          - {NAME}-decode.inference-system.svc.cluster.local
        options:
          - name: ndots
            value: "5"
      containers:
      - name: {NAME}
        # args:
        # - sh
        # - -c
        # - "bash -x /scripts/entrypoint.sh"
        image: {IMAGE}
        imagePullPolicy: Always
        command: ["bash", "/pd/scripts/entrypoint.sh"]
        ports:
          - containerPort: 8000
        env:
        - name: SERVER_NAME
          value: "{NAME}"
        - name: PD_ROLE
          value: "{MINILB_PD_ROLE}"
        volumeMounts:
          - name: model-path
            mountPath: /models
          - name: shm-volume
            mountPath: /dev/shm
          - name: script-path
            mountPath: /pd/scripts
      volumes:
        - name: model-path
          hostPath:
            path: /data
        - name: shm-volume
          emptyDir:
            medium: Memory
        - name: script-path
          hostPath:
            path: /root/hz/scripts